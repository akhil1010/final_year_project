{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.962413\n",
      "[200]\tvalid_0's auc: 0.967733\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.968674\n",
      "Important features:\n",
      "[('ip', 965), ('channel', 799), ('app', 794), ('ip_df_day_click_time_df_hour_click_time_count_channel', 614), ('os', 522), ('device', 148), ('ip_app_count_channel', 127), ('ip_app_os_count_channel', 58), ('ip_app_df_day_click_time_df_hour_click_time_count_channel', 18)]\n",
      "0 AUC: 0.9686744932936384\n",
      "AUC = 0.968674 +/- 0.000000\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/amitkumarjaiswal/talking-data-adtracking-fraud-detection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import gc\n",
    "\n",
    "def extractDateFeatures(df, sourceName):\n",
    "    seasons = [0,0,1,1,1,2,2,2,3,3,3,0] #dec - feb is winter, then spring, summer, fall etc\n",
    "    df['df_day_' + sourceName] = pd.to_datetime(df[sourceName]).dt.day.astype('uint8')\n",
    "    df['df_weekday_' + sourceName] = pd.to_datetime(df[sourceName]).dt.dayofweek.astype('uint8')\n",
    "    df['df_hour_' + sourceName] = pd.to_datetime(df[sourceName]).dt.hour.astype('uint8')\n",
    "\n",
    "dtypes = {s\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }    \n",
    "\n",
    "train=pd.read_csv(\"../input/train_sample.csv\",\\\n",
    "                 dtype=dtypes)\n",
    "extractDateFeatures(train,'click_time')\n",
    "\n",
    "GROUPBY_AGGREGATIONS = [\n",
    "    # Variance in day, for ip-app-channel\n",
    "    {'groupby': ['ip','app','channel'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "    # Variance in day, for ip-app-device\n",
    "    {'groupby': ['ip','app','device'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "    # Variance in day, for ip-app-os\n",
    "    {'groupby': ['ip','app','os'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "\n",
    "    # Count, for ip-day-hour\n",
    "    {'groupby': ['ip','df_day_click_time','df_hour_click_time'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    \n",
    "    # Count, for ip-app\n",
    "    {'groupby': ['ip', 'app'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},        \n",
    "    # Count, for ip-app-os\n",
    "    {'groupby': ['ip', 'app', 'os'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    # Count, for ip-app-day-hour\n",
    "    {'groupby': ['ip','app','df_day_click_time','df_hour_click_time'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    \n",
    "    # Mean hour, for ip-app-channel\n",
    "    {'groupby': ['ip','app','channel'], 'select': 'df_hour_click_time', 'agg': 'mean', 'type': 'float32', 'type': 'float32'}\n",
    "]\n",
    "test=pd.read_csv(\"../input/test.csv\"\\\n",
    "                 ,nrows=1000000, dtype=dtypes)\n",
    "extractDateFeatures(test,'click_time')\n",
    "for spec in GROUPBY_AGGREGATIONS:\n",
    "    # Unique list of features to select\n",
    "    all_features = list(set(spec['groupby'] + [spec['select']]))\n",
    "    # Name of new feature\n",
    "    new_feature = '{}_{}_{}'.format('_'.join(spec['groupby']), spec['agg'], spec['select'])\n",
    "     # Perform the groupby\n",
    "    gp = train[all_features]. \\\n",
    "        groupby(spec['groupby'])[spec['select']]. \\\n",
    "        agg(spec['agg']). \\\n",
    "        reset_index(). \\\n",
    "        rename(index=str, columns={spec['select']: new_feature}).astype(spec['type'])\n",
    "     # Merge back to X_train\n",
    "    train = train.merge(gp, on=spec['groupby'], how='left')\n",
    "    \n",
    "    gp = test[all_features]. \\\n",
    "        groupby(spec['groupby'])[spec['select']]. \\\n",
    "        agg(spec['agg']). \\\n",
    "        reset_index(). \\\n",
    "        rename(index=str, columns={spec['select']: new_feature}).astype(spec['type'])\n",
    "     # Merge back to X_train\n",
    "    test = test.merge(gp, on=spec['groupby'], how='left')\n",
    "    \n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "train.fillna(0,inplace=True)\n",
    "test.fillna(0,inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = train['is_attributed']\n",
    "x_train = train.drop(['is_attributed','click_time','attributed_time'],axis=1)\n",
    "y_test = train['is_attributed']\n",
    "x_test = test.drop(['click_time'],axis=1)\n",
    "\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 2\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   \n",
    "\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 12,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 4,\n",
    "        'lambda_l2': 1.5,\n",
    "        'min_gain_to_split': 0,\n",
    "    }  \n",
    "\n",
    "for train_index, valid_index in kf.split(x_train):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb.Dataset(x_train.loc[train_index], y_train.loc[train_index], feature_name=x_train.columns.tolist()),\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb.Dataset(x_train.loc[valid_index], y_train.loc[valid_index])],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        print(tuples[:200])\n",
    "\n",
    "    p = model.predict(x_train.loc[valid_index], num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y_train.loc[valid_index], p)\n",
    "\n",
    "    print('{} AUC: {}'.format(cnt, auc))\n",
    "\n",
    "    p = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p)\n",
    "    else:\n",
    "        p_buf += np.array(p)\n",
    "    auc_buf.append(auc)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 0: # Comment this to run several folds\n",
    "        break\n",
    "    \n",
    "    '''del model\n",
    "    gc.collect'''\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n",
    "\n",
    "preds = p_buf/cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
